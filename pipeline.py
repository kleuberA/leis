"""
pipeline.py â€” v2
Orquestra o pipeline completo: download â†’ parse â†’ cross-refs â†’ validaÃ§Ã£o.

Novidades v2:
  - Suporte a mÃºltiplas leis por cÃ³digo do catÃ¡logo (config/leis.yaml)
  - ExtraÃ§Ã£o de cross-references em JSON separado
  - Modo batch: processa vÃ¡rias leis em sequÃªncia
  - RelatÃ³rio de precisÃ£o com threshold configurÃ¡vel

Uso:
    python pipeline.py                         # LDB (padrÃ£o)
    python pipeline.py --lei 9394
    python pipeline.py --lei 10406             # CÃ³digo Civil
    python pipeline.py --batch 9394 8078 clt  # MÃºltiplas leis
    python pipeline.py --url URL --codigo xyz  # URL avulsa
    python pipeline.py --listar               # Lista leis disponÃ­veis
    python pipeline.py --sem-cache            # ForÃ§a re-download
"""

import argparse
import json
import logging
import sys
from pathlib import Path

from downloader import baixar_lei, baixar_lei_url, listar_leis, info_lei
from parser import parse_lei, _iterar_artigos_mut
from validator import validar_estrutura, imprimir_relatorio
from crossref import extrair_crossrefs_estrutura
from smart_parser import smart_parser

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
)
logger = logging.getLogger(__name__)

# Threshold mÃ­nimo de qualidade para nÃ£o falhar o pipeline
PRECISAO_MINIMA_ARTIGOS = 0.95    # 95% dos artigos devem ter estrutura


def run(
    codigo: str,
    url: str | None = None,
    fonte: str = "planalto",
    usar_cache: bool = True,
    extrair_refs: bool = True,
    saida_dir: Path | None = None,
) -> dict:
    """
    Executa o pipeline completo para uma lei.

    Args:
        codigo:      CÃ³digo da lei (para IDs, nomes de arquivo, e lookup no catÃ¡logo).
        url:         URL direta (opcional). Se omitida, usa o catÃ¡logo.
        fonte:       Fonte para adapter quando url Ã© fornecida diretamente.
        usar_cache:  Se True, usa HTML em cache quando disponÃ­vel.
        extrair_refs: Se True, extrai cross-references e salva JSON.
        saida_dir:   DiretÃ³rio de saÃ­da. PadrÃ£o: diretÃ³rio atual.

    Returns:
        Dict com 'estrutura', 'relatorio', e opcionalmente 'crossrefs'.
    """
    base = saida_dir or Path(".")
    base.mkdir(parents=True, exist_ok=True)

    saida_txt   = base / f"raw_{codigo}.txt"
    saida_json  = base / f"struct_{codigo}.json"
    saida_relat = base / f"relatorio_{codigo}.json"
    saida_refs  = base / f"crossrefs_{codigo}.json"

    # Resolve nome da lei para logs
    cfg_lei  = info_lei(codigo) or {}
    nome_lei = cfg_lei.get("nome", f"Lei {codigo}")

    logger.info(f"{'â•'*55}")
    logger.info(f"  Pipeline: {nome_lei}")
    logger.info(f"{'â•'*55}")

    # â”€â”€ ETAPA 1: Download â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    logger.info(f"[1/4] Download")
    if url:
        texto = baixar_lei_url(url, fonte=fonte, usar_cache=usar_cache)
    else:
        texto = baixar_lei(codigo, usar_cache=usar_cache)

    saida_txt.write_text(texto, encoding="utf-8")
    logger.info(f"      Texto salvo: {saida_txt} ({len(texto):,} chars)")

    # â”€â”€ ETAPA 2: Parse â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    logger.info(f"[2/4] Parse")
    estrutura = parse_lei(texto, codigo_lei=codigo)
    saida_json.write_text(
        json.dumps(estrutura, ensure_ascii=False, indent=2),
        encoding="utf-8",
    )
    logger.info(f"      JSON salvo: {saida_json}")

    # â”€â”€ ETAPA 2.5: Smart Repair (IA) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if smart_parser.enabled:
        logger.info(f"[2.5] Smart Repair (IA)")
        reparados = 0
        for art in _iterar_artigos_mut(estrutura):
            if art.get("confianca", 1.0) < 0.7:
                texto_bruto = art.get("texto_bruto")
                if not texto_bruto: continue
                
                novo_art = smart_parser.recuperar_artigo(texto_bruto, art.get("numero", ""))
                if novo_art:
                    # Atualiza o nÃ³ mantendo ID e Ordem originais
                    art["numero"]    = novo_art.get("numero", art["numero"])
                    art["estrutura"] = novo_art.get("estrutura", art["estrutura"])
                    art["confianca"] = novo_art.get("confianca_ia", 0.9)
                    art["reparado_ia"] = True
                    reparados += 1
                    
        if reparados:
            logger.info(f"      {reparados} artigos reparados via IA.")
            saida_json.write_text(json.dumps(estrutura, ensure_ascii=False, indent=2), encoding="utf-8")

    # â”€â”€ ETAPA 3: Cross-references â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    crossrefs = []
    if extrair_refs:
        logger.info(f"[3/4] Cross-references")
        crossrefs = extrair_crossrefs_estrutura(estrutura, codigo_lei=codigo)
        saida_refs.write_text(
            json.dumps(crossrefs, ensure_ascii=False, indent=2),
            encoding="utf-8",
        )
        logger.info(f"      {len(crossrefs)} referÃªncias salvas: {saida_refs}")
    else:
        logger.info(f"[3/4] Cross-references (pulado)")

    # â”€â”€ ETAPA 4: ValidaÃ§Ã£o + guarda de precisÃ£o â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    logger.info(f"[4/4] ValidaÃ§Ã£o")
    relatorio = validar_estrutura(estrutura)
    saida_relat.write_text(
        json.dumps(relatorio, ensure_ascii=False, indent=2),
        encoding="utf-8",
    )
    imprimir_relatorio(relatorio)
    logger.info(f"      RelatÃ³rio salvo: {saida_relat}")

    # Verifica threshold de qualidade
    total   = relatorio.get("total_artigos", 0)
    vazios  = len(relatorio.get("artigos_vazios", []))
    if total > 0:
        precisao = 1.0 - (vazios / total)
        if precisao < PRECISAO_MINIMA_ARTIGOS:
            logger.error(
                f"REGRESSÃƒO DE PRECISÃƒO: {precisao:.1%} < {PRECISAO_MINIMA_ARTIGOS:.0%} "
                f"({vazios}/{total} artigos vazios)"
            )
            sys.exit(2)
        else:
            logger.info(f"      PrecisÃ£o estrutural: {precisao:.1%} âœ“")

    return {"estrutura": estrutura, "relatorio": relatorio, "crossrefs": crossrefs}


def run_batch(
    codigos: list[str],
    usar_cache: bool = True,
    saida_dir: Path | None = None,
) -> list[dict]:
    """
    Processa mÃºltiplas leis em sequÃªncia.
    Continua mesmo se uma lei falhar, reportando os erros no final.
    """
    resultados = []
    erros = []

    for i, codigo in enumerate(codigos, 1):
        logger.info(f"\n[{i}/{len(codigos)}] Processando lei: {codigo}")
        try:
            resultado = run(
                codigo=codigo,
                usar_cache=usar_cache,
                saida_dir=saida_dir,
            )
            resultados.append({"codigo": codigo, "status": "ok", **resultado})
        except KeyError as e:
            msg = f"Lei '{codigo}' nÃ£o encontrada no catÃ¡logo"
            logger.error(msg)
            erros.append({"codigo": codigo, "erro": msg})
        except Exception as e:
            msg = str(e)
            logger.error(f"Falha ao processar lei {codigo}: {msg}")
            erros.append({"codigo": codigo, "erro": msg})

    # SumÃ¡rio do batch
    logger.info(f"\n{'â•'*55}")
    logger.info(f"  BATCH CONCLUÃDO: {len(resultados)} ok, {len(erros)} erro(s)")
    if erros:
        for e in erros:
            logger.error(f"  âœ— {e['codigo']}: {e['erro']}")
    logger.info(f"{'â•'*55}")

    return resultados


def suggest_config(url: str, nome: str = "") -> dict:
    """Gera uma sugestÃ£o de configuraÃ§Ã£o para o leis.yaml a partir da URL."""
    from downloader import baixar_lei_url
    from parser import parse_lei
    
    print(f"ğŸ” Analisando URL para sugestÃ£o de config: {url}")
    try:
        texto = baixar_lei_url(url, usar_cache=True)
        # Tenta inferir o cÃ³digo do final da URL
        sugestao_codigo = Path(url).stem.replace("l", "").replace("compilado", "").replace("compilada", "")
        if not sugestao_codigo: sugestao_codigo = "nova_lei"
        
        estrutura = parse_lei(texto, codigo_lei=sugestao_codigo)
        
        # InfeÃ§Ã£o bÃ¡sica de tags
        tags = []
        if "penal" in nome.lower() or "crime" in nome.lower(): tags.append("penal")
        if "civil" in nome.lower(): tags.append("civil")
        
        config = {
            sugestao_codigo: {
                "nome": nome or estrutura.get("lei", {}).get("ementa", "Nova Lei")[:60] + "...",
                "url": url,
                "fonte": "planalto" if "planalto.gov.br" in url else "auto",
                "encoding": "latin-1" if "planalto.gov.br" in url else "utf-8",
                "tags": tags
            }
        }
        return config
    except Exception as e:
        print(f"âŒ Erro ao sugerir config: {e}")
        return {}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# CLI
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    ap = argparse.ArgumentParser(
        description="Pipeline de scraping de leis brasileiras v2"
    )

    grupo = ap.add_mutually_exclusive_group()
    grupo.add_argument("--lei",    help="CÃ³digo de uma lei do catÃ¡logo (ex: 9394)")
    grupo.add_argument("--batch",  nargs="+", metavar="CODIGO",
                       help="MÃºltiplos cÃ³digos para processamento em lote")
    grupo.add_argument("--listar", action="store_true",
                       help="Lista todas as leis disponÃ­veis no catÃ¡logo")
    grupo.add_argument("--suggest", nargs=2, metavar=("URL", "NOME"),
                       help="Sugerir configuraÃ§Ã£o para uma nova lei")

    ap.add_argument("--url",    help="URL direta (ignora catÃ¡logo, requer --codigo)")
    ap.add_argument("--codigo", help="CÃ³digo da lei ao usar --url")
    ap.add_argument("--fonte",  default="planalto",
                    choices=["planalto", "senado", "camara"],
                    help="Fonte para --url (padrÃ£o: planalto)")
    ap.add_argument("--sem-cache", action="store_true",
                    help="ForÃ§a re-download mesmo com cache disponÃ­vel")
    ap.add_argument("--sem-refs", action="store_true",
                    help="Pula extraÃ§Ã£o de cross-references")
    ap.add_argument("--review", action="store_true",
                    help="Gera relatÃ³rio de revisÃ£o HTML apÃ³s o processamento")
    ap.add_argument("--saida", default=".",
                    help="DiretÃ³rio de saÃ­da dos arquivos (padrÃ£o: .)")

    args = ap.parse_args()

    if args.listar:
        print("\nLeis disponÃ­veis no catÃ¡logo:\n")
        from downloader import listar_leis
        for cod, nome in listar_leis().items():
            print(f"  {cod:12} {nome}")
        print()
        return

    if args.suggest:
        import yaml
        sugestao = suggest_config(args.suggest[0], args.suggest[1])
        print("\n--- SUGESTÃƒO PARA config/leis.yaml ---")
        print(yaml.dump(sugestao, allow_unicode=True, default_flow_style=False))
        return

    saida_dir  = Path(args.saida)
    usar_cache = not args.sem_cache
    extrair    = not args.sem_refs

    if args.batch:
        run_batch(args.batch, usar_cache=usar_cache, saida_dir=saida_dir)
    elif args.url:
        if not args.codigo:
            ap.error("--url requer --codigo")
        run(
            codigo=args.codigo,
            url=args.url,
            fonte=args.fonte,
            usar_cache=usar_cache,
            extrair_refs=extrair,
            saida_dir=saida_dir,
        )
        if args.review:
            from review_viewer import generate_review_html
            generate_review_html(f"struct_{args.codigo}.json", f"raw_{args.codigo}.txt", f"review_{args.codigo}.html")
    elif args.lei:
        run(
            codigo=args.lei,
            usar_cache=usar_cache,
            extrair_refs=extrair,
            saida_dir=saida_dir,
        )
        if args.review:
            from review_viewer import generate_review_html
            generate_review_html(f"struct_{args.lei}.json", f"raw_{args.lei}.txt", f"review_{args.lei}.html")
    else:
        # PadrÃ£o: LDB
        logger.info("Nenhuma lei especificada â€” usando padrÃ£o: LDB (9394)")
        run(
            codigo="9394",
            usar_cache=usar_cache,
            extrair_refs=extrair,
            saida_dir=saida_dir,
        )


if __name__ == "__main__":
    main()